{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21a390d",
   "metadata": {},
   "source": [
    "top 可以看 cpu 狀態\n",
    "sudo powermetrics --samplers cpu_power,gpu_power --show-initial-usage 可以看到 GPU 狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install experiment-impact-tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549898b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "CPU usage factor: 1.10\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import time\n",
    "\n",
    "p = psutil.Process()\n",
    "start_cpu = p.cpu_times().user + p.cpu_times().system\n",
    "start_wall = time.time()\n",
    "\n",
    "print(\"starting\")\n",
    "# ... your code here ...\n",
    "\n",
    "end_cpu = p.cpu_times().user + p.cpu_times().system\n",
    "end_wall = time.time()\n",
    "\n",
    "cpu_usage_factor = (end_cpu - start_cpu) / (end_wall - start_wall)\n",
    "print(f\"CPU usage factor: {cpu_usage_factor:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad132e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "# false means there are no GPUs available\n",
    "print(torch.backends.mps.is_available()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb877e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'json_normalize' from 'pandas.io.json' (/Users/lulu/miniconda3/lib/python3.12/site-packages/pandas/io/json/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtempfile\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mexperiment_impact_tracker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompute_tracker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImpactTracker\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[34;01mExperiment\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/experiment_impact_tracker/compute_tracker.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpsutil\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mujson\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mjson\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjson\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_normalize\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mexperiment_impact_tracker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rapl\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mexperiment_impact_tracker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpu\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_my_cpu_info\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'json_normalize' from 'pandas.io.json' (/Users/lulu/miniconda3/lib/python3.12/site-packages/pandas/io/json/__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "from experiment_impact_tracker.compute_tracker import ImpactTracker\n",
    "\n",
    "\n",
    "class Experiment:\n",
    "    def __init__(self):\n",
    "        device = torch.device(\"cpu\")\n",
    "        # device = torch.device('cuda') # Uncomment this to run on GPU\n",
    "\n",
    "        # N is batch size; D_in is input dimension;\n",
    "        # H is hidden dimension; D_out is output dimension.\n",
    "        N, D_in, H, D_out = 1024, 10000, 1000, 100\n",
    "\n",
    "        # Create random input and output data\n",
    "        self.x = torch.randn(N, D_in, device=device)\n",
    "        self.y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "        # Randomly initialize weights\n",
    "        self.w1 = torch.randn(D_in, H, device=device)\n",
    "        self.w2 = torch.randn(H, D_out, device=device)\n",
    "        self.learning_rate = 1e-6\n",
    "\n",
    "    def train(self):\n",
    "        # Forward pass: compute predicted y\n",
    "        h = self.x.mm(self.w1)\n",
    "        h_relu = h.clamp(min=0)\n",
    "        y_pred = h_relu.mm(self.w2)\n",
    "\n",
    "        # Compute and print loss; loss is a scalar, and is stored in a PyTorch Tensor\n",
    "        # of shape (); we can get its value as a Python number with loss.item().\n",
    "        loss = (y_pred - self.y).pow(2).sum()\n",
    "\n",
    "        # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "        grad_y_pred = 2.0 * (y_pred - self.y)\n",
    "        grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "        grad_h_relu = grad_y_pred.mm(self.w2.t())\n",
    "        grad_h = grad_h_relu.clone()\n",
    "        grad_h[h < 0] = 0\n",
    "        grad_w1 = self.x.t().mm(grad_h)\n",
    "\n",
    "        # Update weights using gradient descent\n",
    "        self.w1 -= self.learning_rate * grad_w1\n",
    "        self.w2 -= self.learning_rate * grad_w2\n",
    "\n",
    "\n",
    "def my_experiment() -> None:\n",
    "    tmp_dir = tempfile.mkdtemp()\n",
    "    # Init tracker with log path\n",
    "    tracker = ImpactTracker(tmp_dir)\n",
    "    # Start tracker in a separate process\n",
    "    tracker.launch_impact_monitor()\n",
    "\n",
    "    exp = Experiment()\n",
    "\n",
    "    for t in range(100):\n",
    "        if t % 10 == 9:\n",
    "            print(f\"Pass: {t}\")\n",
    "            # Optional. Adding this will ensure that your experiment stops if impact tracker throws an exception and exit.\n",
    "            tracker.get_latest_info_and_check_for_errors()\n",
    "        exp.train()\n",
    "\n",
    "    print(f\"Please find your experiment logs in: {tmp_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    my_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
